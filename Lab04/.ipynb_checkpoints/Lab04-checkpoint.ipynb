{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 4 - algorytm normalizacja, selekcja cech.\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest przeprowadzenie normalizacji i selekcji cech.\n",
    "\n",
    "### Termin\n",
    "Zadanie nale偶y wykona tego samego dnia. \n",
    "\n",
    "### System oceniania\n",
    "\n",
    "| Liczba punkt贸w (procentowo) | Ocena |\n",
    "| :----                    | ---: |\n",
    "| [0-50)   | 2   |\n",
    "| [50-60)  | 3   |\n",
    "| [60-70)  | 3.5 |\n",
    "| [70-80)  | 4   |\n",
    "| [80-90)  | 4.5 |\n",
    "| [90-100] | 5   |\n",
    "\n",
    "<u>Punkty ujemne</u>\n",
    "\n",
    "* `ocena - 0.5` je偶eli zadanie wysano po laboratorium, ale < 7 dni; \n",
    "* `ocena - 1` je偶eli zadanie wysano w terminie pomidzy 7 a 14 dni;\n",
    "* `ocena - 1.5` je偶eli zadanie wysano po upywie 14 dni, ale przed ostatnim laboratorium;\n",
    "* `ocena = 2` je偶eli zadanie wysano po ostatnim laboratorium.\n",
    "\n",
    "<u>Uwaga:</u>\n",
    "\n",
    "Niedopuszczalne jest dzielenie si notatnikiem (plik `.ipynb`) z innymi studentami ani udostpnianie go w Internecie. Ka偶dy student powinien pobra notatnik samodzielnie z platformy WIKAMP.\n",
    "Wysyajc zadanie potwierdasz, 偶e wykonae je samodzielnie i jest to Twoja indywidualna praca a materia przedstawiony w tej pracy jest dla Ciebie zrozumiay. Prace bardzo podobne albo grupowe bd uznawane za plagiat.\n",
    "\n",
    "\n",
    "### Zbi贸r danych\n",
    "\n",
    "Zbi贸r danych znajduje si w katalogu `dataset/*`. Jest to zmodyfikowany zbi贸r danych znajdujcy si pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyanie zada\n",
    "\n",
    "Wszystkie pliki nale偶y spakowa archiwizatorem **zip** i przesa za porednictwem platformy WIKAMP. Poni偶ej oczekiwana zawarto archiwum:\n",
    "\n",
    "```\n",
    "+--  [IMIE.NAZWISKO].zip\n",
    "    +--  Lab04.ipynb\n",
    "    +--  dataset\n",
    "        +--  dataset.npz\n",
    "        +--  ReadMe.pdf\n",
    "```\n",
    "\n",
    "**Pamitaj, wyniki powinny by czytelnie opisane oraz zaprezentowane graficznie (je偶eli jest taka mo偶liwo). Warstwa prezentacji danych to jeden z g贸wnych element贸w wpywajcych na ocen.**\n",
    "\n",
    "Przykad (na podstawie tablicy pomyek):\n",
    "\n",
    "**殴le** (nie wiadomo co jest poni偶ej zaprezentowane, kolumny ani wiersze nie s podpisane, nie wiadomo kt贸re z nich prezentuj predykcje, a kt贸re waciwe etykiety):\n",
    "```\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "```\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Nale偶y wykona nastpujce czynnoci w celu realizacji niniejszego zadania:\n",
    "\n",
    "#### Normalizacja\n",
    "* Wczytaj dane.\n",
    "* Znormalizuj dane.\n",
    "* Przeprowad藕 eksperyment z zastosowaniem algorytmu kNN lub NM dla danych znormalizowanych oraz bez normalizacji.\n",
    "    * W eksperymencie wybierz minimum 5 klas oraz 10 cech.\n",
    "* Przedstaw por贸wnanie wynik贸w klasyfikacji na danych znormalizowanych i bez normalizacji.\n",
    "* Napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 16)\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "[1.00000000e+00 6.42857143e+00 8.04829893e-01 1.70366987e+00\n",
      " 4.25848188e-01 9.73543273e-01 9.93903017e-01 7.73864549e-01\n",
      " 5.79951347e-03 3.87482009e-03 2.03802164e-02 7.15419902e-02\n",
      " 6.15755177e-03 1.86811787e-03 1.02716254e-04 5.83331644e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-9fe488ef178e>:83: RuntimeWarning: Mean of empty slice.\n",
      "  classMeans = [train[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "<ipython-input-1-9fe488ef178e>:84: RuntimeWarning: Mean of empty slice.\n",
      "  classMeansNormalized = [train_normalized[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import operator\n",
    "from random import randint\n",
    "\n",
    "ATTRIBUTE_NAMES = [\"Class\", \"Specimen No.\", \"Eccentricity\", \"Aspect Ratio\", \"Elongation\", \"Solidity\", \"Stochastic Convexity\", \"Isoperimetric Factor\", \"Maximal Indentation Depth\", \"Lobedness\", \"Average Intensity\", \"Average Contrast\", \"Smoothness\", \"Third moment\", \"Uniformity\", \"Entropy\"]\n",
    "CLASS_NAMES = \\\n",
    "\"\"\"Quercus suber \n",
    "Salix atrocinera \n",
    "Populus nigra \n",
    "Alnus sp. \n",
    "Quercus robur \n",
    "Crataegus monogyna \n",
    "Ilex aquifolium \n",
    "Nerium oleander \n",
    "Betula pubescens \n",
    "Tilia tomentosa \n",
    "Acer palmatum \n",
    "Celtis sp. \n",
    "Corylus avellana \n",
    "Castanea sativa \n",
    "Populus alba \n",
    "Acer negundo \n",
    "Taxus bacatta \n",
    "Papaver sp. \n",
    "Polypolium vulgare \n",
    "Pinus sp. \n",
    "Fraxinus sp. \n",
    "Primula vulgaris \n",
    "Erodium sp. \n",
    "Bougainvillea sp. \n",
    "Arisarum vulgare \n",
    "Euonymus japonicus \n",
    "Ilex perado ssp. azorica \n",
    "Magnolia soulangeana \n",
    "Buxus sempervirens \n",
    "Urtica dioica \n",
    "Podocarpus sp. \n",
    "Acca sellowiana \n",
    "Hydrangea sp. \n",
    "Pseudosasa japonica \n",
    "Magnolia grandiflora \n",
    "Geranium sp. \n",
    "Aesculus californica \n",
    "Chelidonium majus \n",
    "Schinus terebinthifolius \n",
    "Fragaria vesca \"\"\".split(\"\\n\")\n",
    "# import data\n",
    "import numpy as np\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "    train, test = data['train'], data['test']\n",
    "print(train.shape) # verify shape\n",
    "\n",
    "def normalize_array_columns(a, column_indices):\n",
    "    for index in column_indices:\n",
    "        a[:, index] = (a[:,index] - a[:,index].min()) / (a[:,index].max() - a[:,index].min())\n",
    "    return a\n",
    "\n",
    "train_normalized = normalize_array_columns(train.copy(), range(2,16))\n",
    "test_normalized = normalize_array_columns(test.copy(), range(2,16))\n",
    "print(train_normalized[:,2:16].min(), train_normalized[:,2:16].max())\n",
    "print(test_normalized[:,2:16].min(), train_normalized[:,2:16].max())\n",
    "     \n",
    "CLASS_COUNT = 40\n",
    "\n",
    "classIndexes = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexes.append([])\n",
    "for i, sample in enumerate(train):\n",
    "    classIndexes[int(sample[0])-1].append(int(i))\n",
    "\"\"\"\n",
    "for i, sampleClass in enumerate(classIndexes):\n",
    "    print(i,len(sampleClass))\n",
    "\"\"\"\n",
    "classIndexesTest = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexesTest.append([])\n",
    "for i, sample in enumerate(test):\n",
    "    classIndexesTest[int(sample[0])-1].append(int(i))\n",
    "\n",
    " \n",
    "classMeans = [train[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n",
    "classMeansNormalized = [train_normalized[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n",
    "print(classMeans[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_nm_machalan(test_sample, class_means, class_indices, attribute_indices, class_cov_matrices):\n",
    "    diff_vect = np.array(test_sample[attribute_indices]-class_means[class_indices][0][attribute_indices])\n",
    "    comat = np.linalg.inv(class_cov_matrices[class_indices[0]])\n",
    "    min_dist = np.sqrt(np.matmul(np.matmul(diff_vect,comat),diff_vect))\n",
    "    min_class = 0\n",
    "    for i, m in enumerate(class_means[class_indices]):\n",
    "        diff_vect = np.array(test_sample[attribute_indices]-class_means[class_indices][i][attribute_indices])\n",
    "        comat = np.linalg.inv(class_cov_matrices[class_indices[i]])\n",
    "        d = np.sqrt(np.matmul(np.matmul(diff_vect,comat),diff_vect))\n",
    "        if(d < min_dist):\n",
    "            min_dist = d\n",
    "            min_class = i\n",
    "    return class_indices[min_class];\n",
    "        \n",
    "\n",
    "def covariance_matrix(samples, rowvar=False):\n",
    "    var_axis = 0 if rowvar else 1\n",
    "    samp_axis = 1 if rowvar else 0\n",
    "    mean = samples.mean(axis=samp_axis)\n",
    "    result = np.zeros((samples.shape[var_axis], samples.shape[var_axis]))\n",
    "    if(rowvar):\n",
    "        for sample in samples.T:\n",
    "            p = np.outer((sample - mean), (sample - mean))\n",
    "            result += p\n",
    "    else:\n",
    "        for sample in samples:\n",
    "            p = np.outer((sample - mean), (sample - mean))\n",
    "            result += p\n",
    "    result /= samples.shape[samp_axis]-1\n",
    "    return result\n",
    "    \n",
    "def run_nm_test(train_array, test_array, class_means, classes, attributes):\n",
    "    chosen_train_samples = np.concatenate(\n",
    "        [train_array[classIndexes[i],:] for i in classes],\n",
    "        axis=0\n",
    "    ) # pick train samples from chosen classes\n",
    "    chosen_test_samples = np.concatenate(\n",
    "        [test_array[classIndexesTest[i],:] for i in classes],\n",
    "        axis=0\n",
    "    ) # filter out test samples that do not belong to the chosen classes\n",
    "    \n",
    "    test_classes = [sample[0] for sample in chosen_test_samples] # pick indices of classes that are tested\n",
    "\n",
    "    classCovMatrices = []\n",
    "    for i in range(CLASS_COUNT):\n",
    "        try:\n",
    "            # calculate covariance matrix only for selected attributes\n",
    "            classCovMatrices.append(covariance_matrix(train_array[classIndexes[i]][:,attributes]))\n",
    "        except:\n",
    "            classCovMatrices.append(None)\n",
    "    test_nearest_means = \\\n",
    "        [\n",
    "            1+int(assign_nm_machalan(test_sample, np.array(class_means), classes, attributes, classCovMatrices)) # pick only these means that are from the chosen classes(cast to np.array to be able to slice it with a list)    \n",
    "            for test_sample in chosen_test_samples # for each test sample from the chosen ones (i.e. belonging to the chosen classes)\n",
    "        ]\n",
    "    \n",
    "    totalTestSamples = chosen_test_samples.shape[0]\n",
    "    correctSamples = 0\n",
    "    for i, sample in enumerate(chosen_test_samples):\n",
    "        if(test_nearest_means[i] == sample[0]): correctSamples+=1\n",
    "\n",
    "    return {\n",
    "        \"total_samples\": totalTestSamples,\n",
    "        \"correct_samples\": correctSamples,\n",
    "        \"confusion_matrix\": confusion_matrix(test_classes, test_nearest_means)\n",
    "    }\n",
    "\n",
    "def print_test_result(r:dict, matrix_class_indexes=None):\n",
    "    \"\"\" Prints formatted result dict of run_knn_test()\n",
    "    \"\"\"\n",
    "    print(\"MN: {} correct out of {} total. Accuracy: {:.2f}%\".format(r['correct_samples'], r['total_samples'], r['correct_samples']/r['total_samples']*100))\n",
    "    if(matrix_class_indexes):\n",
    "        print(\"{:8.8s}\".format(\"TRU\\PRED\"),end='|')\n",
    "        for index in matrix_class_indexes: #print top row\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[index]),end='|')\n",
    "        print()\n",
    "        for i, row in enumerate(r[\"confusion_matrix\"]): #print rows\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[i]),end='|')\n",
    "            for col in row:\n",
    "                print(\"{:8d}\".format(int(col)),end='|')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 CLASSES 10 ATTRIBUTES\n",
      "\n",
      "NORMALIZED\n",
      "MN: 209 correct out of 264 total. Accuracy: 79.17%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRU\\PRED|Quercus |Populus |Podocarp|Acca sel|Hydrange|\n",
      "Quercus |      52|       0|       0|       1|       2|\n",
      "Salix at|       1|      45|       0|       0|       9|\n",
      "Populus |       0|       0|      44|       0|       0|\n",
      "Alnus sp|      13|       0|       0|      13|      29|\n",
      "Quercus |       0|       0|       0|       0|      55|\n",
      "\n",
      "UNNORMALIZED\n",
      "MN: 218 correct out of 264 total. Accuracy: 82.58%\n",
      "TRU\\PRED|Quercus |Populus |Podocarp|Acca sel|Hydrange|\n",
      "Quercus |      55|       0|       0|       0|       0|\n",
      "Salix at|       1|      39|       0|       0|      15|\n",
      "Populus |       0|       0|      44|       0|       0|\n",
      "Alnus sp|      16|       0|       0|      25|      14|\n",
      "Quercus |       0|       0|       0|       0|      55|\n",
      "\n",
      "8 CLASSES 10 ATTRIBUTES\n",
      "\n",
      "NORMALIZED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN: 266 correct out of 396 total. Accuracy: 67.17%\n",
      "TRU\\PRED|Quercus |Populus |Bougainv|Arisarum|Euonymus|Podocarp|Acca sel|Hydrange|\n",
      "Quercus |      19|       0|      25|       0|      11|       0|       0|       0|\n",
      "Salix at|       0|      26|       4|       6|      19|       0|       0|       0|\n",
      "Populus |       0|       0|      50|       0|       7|       0|       0|       9|\n",
      "Alnus sp|       0|       0|       0|      33|       0|       0|       0|       0|\n",
      "Quercus |       0|       0|       0|       0|      33|       0|       0|       0|\n",
      "Crataegu|       0|       0|       0|       0|       0|      44|       0|       0|\n",
      "Ilex aqu|       6|       0|       4|       0|      21|       0|      12|      12|\n",
      "Nerium o|       0|       0|       0|       6|       0|       0|       0|      49|\n",
      "\n",
      "UNNORMALIZED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN: 286 correct out of 396 total. Accuracy: 72.22%\n",
      "TRU\\PRED|Quercus |Populus |Bougainv|Arisarum|Euonymus|Podocarp|Acca sel|Hydrange|\n",
      "Quercus |      27|       0|      13|       0|      15|       0|       0|       0|\n",
      "Salix at|       0|      22|       0|       0|      32|       0|       0|       1|\n",
      "Populus |       0|       0|      52|       0|       9|       0|       0|       5|\n",
      "Alnus sp|       0|       0|       0|      33|       0|       0|       0|       0|\n",
      "Quercus |       2|       0|       0|       0|      31|       0|       0|       0|\n",
      "Crataegu|       0|       0|       0|       0|       0|      44|       0|       0|\n",
      "Ilex aqu|      12|       0|       2|       0|       8|       0|      23|      10|\n",
      "Nerium o|       0|       0|       0|       1|       0|       0|       0|      54|\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5 CLASSES 10 ATTRIBUTES\")\n",
    "PARAM_CLASSES = [0,2,30,31,32]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13,14,15] \n",
    "print(\"\\nNORMALIZED\")\n",
    "print_test_result(run_nm_test(train_normalized, test_normalized, classMeansNormalized, PARAM_CLASSES, PARAM_ATTRIBUTES), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\nUNNORMALIZED\")\n",
    "print_test_result(run_nm_test(train, test, classMeans, PARAM_CLASSES, PARAM_ATTRIBUTES), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\n8 CLASSES 10 ATTRIBUTES\")\n",
    "PARAM_CLASSES = [0,2,23,24,25,30,31,32]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13,14,15] \n",
    "print(\"\\nNORMALIZED\")\n",
    "print_test_result(run_nm_test(train_normalized, test_normalized, classMeansNormalized, PARAM_CLASSES, PARAM_ATTRIBUTES), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\nUNNORMALIZED\")\n",
    "print_test_result(run_nm_test(train, test, classMeans, PARAM_CLASSES, PARAM_ATTRIBUTES), PARAM_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selekcja cech\n",
    "* Przeprowad藕 selekcj cech za pomoc metod poznanych na wykadzie (np. z zastosowaniem wsp贸czynnika Fishera)\n",
    "    * Wybierz 2-5 cech (ze zbioru 10 cech wybranych w poprzednim eksperymencie) i opisz dlaczego je wybrae.\n",
    "* Przeprowad藕 klasyfikacj na wybranych cechach.\n",
    "* Por贸wnaj wyniki klasyfikacji:\n",
    "    * dla 10 cech bez normalizacji,\n",
    "    * dla 10 cech z normalizacj,\n",
    "    * dla 2-5 cech bez normalizacji,\n",
    "    * dla 2-5 cech z normalizacj.\n",
    "* Opisz wyniki i napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 4, 8, 13, 11]\n",
      "\n",
      "5 CLASSES 5 ATTRIBUTES\n",
      "\n",
      "NORMALIZED\n",
      "MN: 181 correct out of 231 total. Accuracy: 78.35%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|Quercus |\n",
      "Quercus |      33|       0|       0|      22|       0|\n",
      "Salix at|      13|      29|       0|       2|       0|\n",
      "Populus |       0|       1|      42|      12|       0|\n",
      "Alnus sp|       0|       0|       0|      22|       0|\n",
      "Quercus |       0|       0|       0|       0|      55|\n",
      "\n",
      "UNNORMALIZED\n",
      "MN: 197 correct out of 231 total. Accuracy: 85.28%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|Quercus |\n",
      "Quercus |      46|       0|       0|       9|       0|\n",
      "Salix at|      12|      32|       0|       0|       0|\n",
      "Populus |       5|       1|      42|       7|       0|\n",
      "Alnus sp|       0|       0|       0|      22|       0|\n",
      "Quercus |       0|       0|       0|       0|      55|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "<ipython-input-2-a1c2d97fafae>:19: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "PARAM_CLASSES = [0,2,30,31,32]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "def compute_1d_fisher(train_array, class_indices, class_means, attr_col, class_a, class_b):\n",
    "    samples_a = train_array[class_indices[class_a], attr_col]\n",
    "    samples_b = train_array[class_indices[class_b], attr_col]\n",
    "    std_a = np.std(samples_a)\n",
    "    std_b = np.std(samples_b)\n",
    "    #print(samples_a, samples_b)\n",
    "    \n",
    "    mean_a = np.mean(samples_a)\n",
    "    mean_b = np.mean(samples_b)\n",
    "    #print(std_a, std_b, mean_a, mean_b)\n",
    "    return np.abs(mean_a-mean_b)/(std_a+std_b)\n",
    "\n",
    "class_pairs = []\n",
    "\n",
    "for i in range(len(PARAM_CLASSES)):\n",
    "    for j in range(i, len(PARAM_CLASSES)):\n",
    "        class_pairs.append((PARAM_CLASSES[i], PARAM_CLASSES[j]))\n",
    "        \n",
    "\n",
    "fisher_results = []\n",
    "for attribute in PARAM_ATTRIBUTES:\n",
    "    average_fisher = 0\n",
    "    for pair in class_pairs:\n",
    "        #average_fisher += compute_1d_fisher(train_normalized, classIndexes, np.array(classMeansNormalized), attribute, pair[0], pair[1])\n",
    "        average_fisher += compute_1d_fisher(train, classIndexes, np.array(classMeans), attribute, pair[0], pair[1])\n",
    "    average_fisher /= len(class_pairs)\n",
    "    fisher_results.append((attribute, average_fisher))\n",
    "    \n",
    "fisher_results.sort(reverse=True, key=lambda x:x[1])\n",
    "good_attributes = [fisher_results[i][0] for i in range(5)]\n",
    "print(good_attributes)\n",
    "\n",
    "class_covariance_matrices = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    class_covariance_matrices.append(covariance_matrix(train[classIndexes[i]][:,PARAM_ATTRIBUTES]))\n",
    "\n",
    "\n",
    "print(\"\\n5 CLASSES 5 ATTRIBUTES\")\n",
    "PARAM_CLASSES = [0,1,2,3,4]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13,14,15] \n",
    "print(\"\\nNORMALIZED\")\n",
    "print_test_result(run_nm_test(train_normalized, test_normalized, classMeansNormalized, PARAM_CLASSES, good_attributes), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\nUNNORMALIZED\")\n",
    "print_test_result(run_nm_test(train, test, classMeans, PARAM_CLASSES, good_attributes), PARAM_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| METHOD                                   | ACCURACY |\n",
    "|------------------------------------------|----------|\n",
    "| 5C/10A Normalized                        | 79.17%   |\n",
    "| 5C/10A Unnormalized                      | 82.58%   |\n",
    "| 5C/5*A Normalized, selected attributes   | 78.35%   |\n",
    "| 5C/5*A Unnormalized, selected attributes | 85.28%   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "f, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "\n",
    "labels = ['5C/10A Normal.', '5C/10A Unnorm.', '5C/5*A Normal.', '5C/5*A Unnorm.']\n",
    "res = [79.17, 82.58, 78.35, 85.28]\n",
    "ax.bar(labels,res)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacja pr贸bek wpyna negatywnie na wyniki klasyfikacji. Wyniki celnoci dla znormalizowanych pr贸bek s o kilka p.p. ni偶sze ni偶 tych nieznormalizowanych. Powodem tego stanu rzeczy jest najprawdopodobniej osiganie wy偶szych wartoci absolutnych przez zestaw kliku lub jednej szczeg贸lnie dyskryminatywnych cech. Poprzez znormalizowanie wartoci przyjmowanych przez cech zlikwidowana zostaje niewiadomie przyznana tej grupie cech wy偶sza waga. \n",
    "\n",
    "Wiele z cech(np. Eccentricity, Isoperimetric Factor) przyjmuje wartoci od 0 do 1 w wyniku operacji matematycznych u偶ytych do ich wyznaczenia, co wyjania w jakim stopniu dlaczego klasyfikatory s w stanie osiga tak wysokie wartoci celnoci bez wykorzystania normalizacji, a potencjalnie dodatkowa normalizacja ma negatywny wpyw na rezultaty.\n",
    "\n",
    "Do selekcji bardziej dyskryminatywnych cech klas zastosowano do prost metod. Policzono jednowymiarowy wsp贸czynnik Fishera dla ka偶dej z cech dla ka偶dej pary wybranych klas i wybrano 5 cech z najwy偶sz wartoci redni dla par klas. Zastosowanie tej metody ograniczyo zestaw cech do 5: Isoperimietric Factor, Elongation, Maximal Indentation Depth, Third moment, Average Contrast.\n",
    "\n",
    "Proces ten doprowadzi do niewielkiego pogorszenia wyniku klasyfikacji dla znormalizowanych pr贸bek i wzrostu celnoci o ok. 3 p.p. dla nieznormalizowanych, sugerujc raczej niewielk u偶yteczno zaproponowanego wykorzystania wsp贸czynnika Fishera. Prawdopodobnie wykorzystanie wielowymiarowej wartoci tego wsp贸czynnika dao by lepsze rezultaty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
