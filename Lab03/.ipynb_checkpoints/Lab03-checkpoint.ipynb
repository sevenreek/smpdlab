{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 3 - algorytm Najbli偶szej redniej (NM)\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest implementacja klasyfikatora najbli偶szej redniej NM (*Nearest Mean*).\n",
    "\n",
    "### Zbi贸r danych\n",
    "\n",
    "Zbi贸r danych znajduje si w `dataset/leaf.csv`. Jest to zbi贸r danych pobrany z adresu: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyanie zada\n",
    "\n",
    "Wszystkie pliki nale偶y spakowa archiwizatorem **zip** i przesa za porednictwem platformy WIKAMP. Poni偶ej oczekiwana zawarto archiwum:\n",
    "\n",
    "```\n",
    "+--  [IMIE I NAZWISKO].zip\n",
    "    +--  Lab03.ipynb\n",
    "    +--  dataset\n",
    "        +--  leaf.csv\n",
    "        +--  ReadMe.pdf\n",
    "```\n",
    "\n",
    "*UWAGA: Wysyajc zadanie potwierdasz, 偶e wykonae je samodzielnie i jest to Twoja indywidualna praca i materia przedstawiony w tej pracy jest dla Ciebie zrozumiay.*\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Nale偶y wykona nastpujce czynnoci w celu realizacji niniejszego zadania:\n",
    "* Wczytaj dane.\n",
    "* Zaimplementuj funkcj, kt贸ra zwraca macierz kowariancji (*uwaga: biblioteka `numpy` posiada gotow implementacj `cov` z kt贸r mo偶esz por贸wna wynik*).\n",
    "\n",
    "\\begin{equation*}\n",
    "C = \\frac{1}{n - 1} \\sum_{i=1}^n (X_i - \\bar X)(X_i - \\bar X)^T\n",
    "\\end{equation*}\n",
    "\n",
    "* **Zaimplementuj klasyfikator najbli偶szej redniej (NM) z zastosowaniem odlegoci Euklidesa**.\n",
    "* **Zaimplementuj klasyfikator najbli偶szej redniej (NM) z zastosowaniem odlegoci Machalanobisa**.\n",
    "\n",
    "    \\begin{equation*}\n",
    "    D_j = \\sqrt{ (x - \\mu_j)^T S_j^{-1}(x - \\mu_j) },\n",
    "    \\end{equation*}\n",
    "\n",
    "    gdzie:\n",
    "    * $D_j$ to odlego klasyfikowanej pr贸bki do $j$-tej klasy (grupy, klastra), \n",
    "    * $\\mu_j$ to wektor ze rednimi wartociami cech w obrbie $j$-tej klasy, \n",
    "    * $S_j^{-1}$ to odwr贸cona macierz kowariancji $j$-tej klasy, \n",
    "    * a $x$ to klasyfikowana pr贸bka.\n",
    "\n",
    "* Opisz wyniki klasyfikator贸w i por贸wnaj je z klasyfikatorem *k*NN (por贸wnaj w kontekcie r贸偶nych metryk - obowizkowo tablica pomyek).\n",
    "\n",
    "> Podpowied藕 1: Do obliczenia macierzy odwrotnej mo偶esz u偶y gotow implementacj, np. funkcj `linalg.inv` z biblioteki `numpy`.\n",
    "\n",
    "> Podpowied藕 2: Do wszelkich podstawowych operacji na macierzach (mno偶enie, transpozycja, dodawanie, odejmowanie, itp.) mo偶esz zastosowa gotow implementacj, np. bibliotek `numpy`.\n",
    "\n",
    "> UWAGA 1: W niniejszym zadaniu jest dowolno implementacji (nie trzeba trzyma si struktury z poprzedniego zadania), jednak algorytm NM nale偶y zaimplementowa samodzielnie bez korzystania z istniajcych rozwiza (jak np. z biblioteki `scikit-learn`).\n",
    "\n",
    "> UWAGA 2: Wszystkie wykonane elementy zadania powinny posiada stosowne komentarze i opisy.\n",
    "\n",
    "\n",
    "**Pamitaj, wyniki powinny by czytelnie opisane oraz zaprezentowane graficznie (je偶eli jest taka mo偶liwo). Warstwa prezentacji danych to jeden z g贸wnych element贸w wpywajcych na ocen.**\n",
    "\n",
    "Przykad (na podstawie tablicy pomyek):\n",
    "\n",
    "殴le (nie wiadomo co jest poni偶ej zaprezentowane, kolumny ani wiersze nie s podpisane, nie wiadomo kt贸re z nich prezentuj predykcje, a kt贸re waciwe etykiety):\n",
    "```\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "```\n",
    "\n",
    "\n",
    "<span style=\"text-decoration:underline\">Referencje</span>\n",
    "\n",
    "1. Mahalanobis, P C, _On test and measures of group divergence : theoretical formulae_, Journal and Proceedings of Asiatic Society of Bengal (New Series) Vol. 26, pp. 541-588. 1930. (URL: http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/1639/029.pdf)\n",
    "2. McLachlan, Goeffrey J. _Mahalanobis distance_, Resonance, pp. 20-26. 1999. (URL: https://www.ias.ac.in/article/fulltext/reso/004/06/0020-0026)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PONI呕EJ WYKONAJ ZADANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 16)\n",
      "MN: 105 correct out of 110 total. Accuracy: 95.45%\n",
      "TRU\\PRED|Populus |Quercus |\n",
      "Quercus |      55|       0|\n",
      "Salix at|       5|      50|\n",
      "\n",
      "EUCLIDEAN DISTANCE\n",
      "MN: 320 correct out of 429 total. Accuracy: 74.59%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|Quercus |Crataegu|Ilex aqu|Nerium o|\n",
      "Quercus |      40|       0|       0|      15|       0|       0|       0|       0|\n",
      "Salix at|      10|      34|       0|       0|       0|       0|       0|       0|\n",
      "Populus |       7|       0|      32|      16|       0|       0|       0|       0|\n",
      "Alnus sp|       6|       1|       1|      14|       0|       0|       0|       0|\n",
      "Quercus |       0|       0|       0|       0|      40|       0|      11|       4|\n",
      "Crataegu|       0|       0|       0|       0|       6|      38|       0|       0|\n",
      "Ilex aqu|       3|      19|       3|       0|       5|       0|      36|       0|\n",
      "Nerium o|       0|       0|       0|       0|       2|       0|       0|      86|\n",
      "\n",
      "MACHALANOBIS' DISTANCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-7c995e0664cc>:79: RuntimeWarning: Mean of empty slice.\n",
      "  classMeans = [train[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "<ipython-input-54-7c995e0664cc>:86: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN: 341 correct out of 429 total. Accuracy: 79.49%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|Quercus |Crataegu|Ilex aqu|Nerium o|\n",
      "Quercus |      44|       0|       0|      11|       0|       0|       0|       0|\n",
      "Salix at|      14|      27|       0|       0|       0|       0|       3|       0|\n",
      "Populus |      12|       0|      37|       5|       0|       0|       1|       0|\n",
      "Alnus sp|       1|       0|       0|      20|       0|       0|       1|       0|\n",
      "Quercus |       0|       0|       0|       0|      55|       0|       0|       0|\n",
      "Crataegu|       0|       0|       0|       0|       0|      44|       0|       0|\n",
      "Ilex aqu|       7|       7|       0|       6|      12|       0|      34|       0|\n",
      "Nerium o|       0|       0|       0|       0|       7|       1|       0|      80|\n",
      "\n",
      "EUCLIDEAN DISTANCE\n",
      "MN: 127 correct out of 176 total. Accuracy: 72.16%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|\n",
      "Quercus |      46|       0|       0|       9|\n",
      "Salix at|      10|      34|       0|       0|\n",
      "Populus |       9|       0|      32|      14|\n",
      "Alnus sp|       5|       1|       1|      15|\n",
      "\n",
      "MACHALANOBIS' DISTANCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-7c995e0664cc>:86: RuntimeWarning: Mean of empty slice.\n",
      "  mean = samples.mean(axis=samp_axis)\n",
      "E:\\ProgramyMiniconda3\\envs\\smpd\\lib\\site-packages\\numpy\\core\\_methods.py:162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MN: 133 correct out of 176 total. Accuracy: 75.57%\n",
      "TRU\\PRED|Quercus |Salix at|Populus |Alnus sp|\n",
      "Quercus |      39|       0|       0|      16|\n",
      "Salix at|      14|      30|       0|       0|\n",
      "Populus |       8|       0|      42|       5|\n",
      "Alnus sp|       0|       0|       0|      22|\n"
     ]
    }
   ],
   "source": [
    "# creates labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import operator\n",
    "from random import randint\n",
    "import warnings\n",
    "\n",
    "\n",
    "# I expect to see RuntimeWarnings in this block\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "ATTRIBUTE_NAMES = [\"Class\", \"Specimen No.\", \"Eccentricity\", \"Aspect Ratio\", \"Elongation\", \"Solidity\", \"Stochastic Convexity\", \"Isoperimetric Factor\", \"Maximal Indentation Depth\", \"Lobedness\", \"Average Intensity\", \"Average Contrast\", \"Smoothness\", \"Third moment\", \"Uniformity\", \"Entropy\"]\n",
    "CLASS_NAMES = \\\n",
    "\"\"\"Quercus suber \n",
    "Salix atrocinera \n",
    "Populus nigra \n",
    "Alnus sp. \n",
    "Quercus robur \n",
    "Crataegus monogyna \n",
    "Ilex aquifolium \n",
    "Nerium oleander \n",
    "Betula pubescens \n",
    "Tilia tomentosa \n",
    "Acer palmatum \n",
    "Celtis sp. \n",
    "Corylus avellana \n",
    "Castanea sativa \n",
    "Populus alba \n",
    "Acer negundo \n",
    "Taxus bacatta \n",
    "Papaver sp. \n",
    "Polypolium vulgare \n",
    "Pinus sp. \n",
    "Fraxinus sp. \n",
    "Primula vulgaris \n",
    "Erodium sp. \n",
    "Bougainvillea sp. \n",
    "Arisarum vulgare \n",
    "Euonymus japonicus \n",
    "Ilex perado ssp. azorica \n",
    "Magnolia soulangeana \n",
    "Buxus sempervirens \n",
    "Urtica dioica \n",
    "Podocarpus sp. \n",
    "Acca sellowiana \n",
    "Hydrangea sp. \n",
    "Pseudosasa japonica \n",
    "Magnolia grandiflora \n",
    "Geranium sp. \n",
    "Aesculus californica \n",
    "Chelidonium majus \n",
    "Schinus terebinthifolius \n",
    "Fragaria vesca \"\"\".split(\"\\n\")\n",
    "# import data\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "    train, test = data['train'], data['test']\n",
    "print(train.shape) # verify shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#assign_k_NN(test[0], train, [4,5], 3)\n",
    "CLASS_COUNT = 40\n",
    "\n",
    "classIndexes = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexes.append([])\n",
    "for i, sample in enumerate(train):\n",
    "    classIndexes[int(sample[0])-1].append(int(i))\n",
    "\"\"\"\n",
    "for i, sampleClass in enumerate(classIndexes):\n",
    "    print(i,len(sampleClass))\n",
    "\"\"\"\n",
    "classIndexesTest = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexesTest.append([])\n",
    "for i, sample in enumerate(test):\n",
    "    classIndexesTest[int(sample[0])-1].append(int(i))\n",
    "\n",
    " \n",
    "classMeans = [train[classIndexes[i]].mean(axis=0) for i in range(CLASS_COUNT)]\n",
    "\n",
    "\n",
    "\n",
    "def covariance_matrix(samples, rowvar=False):\n",
    "    var_axis = 0 if rowvar else 1\n",
    "    samp_axis = 1 if rowvar else 0\n",
    "    mean = samples.mean(axis=samp_axis)\n",
    "    result = np.zeros((samples.shape[var_axis], samples.shape[var_axis]))\n",
    "    if(rowvar):\n",
    "        for sample in samples.T:\n",
    "            p = np.outer((sample - mean), (sample - mean))\n",
    "            result += p\n",
    "    else:\n",
    "        for sample in samples:\n",
    "            p = np.outer((sample - mean), (sample - mean))\n",
    "            result += p\n",
    "    result /= samples.shape[samp_axis]-1\n",
    "    return result\n",
    "\n",
    "def test_covariance_matrix():\n",
    "    #x = np.random.rand(randint(2,4), randint(2,4))\n",
    "    x = np.array([[1,2,3],[3,2,1]])\n",
    "    numpyimpl = np.cov(x, rowvar=True)\n",
    "    myimpl = covariance_matrix(x, rowvar=True)\n",
    "    np.testing.assert_almost_equal(numpyimpl, myimpl)\n",
    "    numpyimpl = np.cov(x, rowvar=False)\n",
    "    myimpl = covariance_matrix(x, rowvar=False)\n",
    "    np.testing.assert_almost_equal(numpyimpl, myimpl)\n",
    "\n",
    "test_covariance_matrix()\n",
    "\n",
    "\n",
    "def assign_nm_euclidean(test_sample, class_means, class_indices, attribute_indices):\n",
    "    min_dist = np.linalg.norm(test_sample[attribute_indices]-class_means[class_indices][0][attribute_indices])\n",
    "    min_class = 0\n",
    "    for i, m in enumerate(class_means[class_indices]):\n",
    "        d = np.linalg.norm(test_sample[attribute_indices]-m[attribute_indices])\n",
    "        if(d < min_dist):\n",
    "            min_dist = d\n",
    "            min_class = i\n",
    "    return class_indices[min_class];\n",
    "\n",
    "\n",
    "def assign_nm_machalan(test_sample, class_means, class_indices, attribute_indices, class_cov_matrices):\n",
    "    diff_vect = np.array(test_sample[attribute_indices]-class_means[class_indices][0][attribute_indices])\n",
    "    comat = np.linalg.inv(class_cov_matrices[class_indices[0]])\n",
    "    min_dist = np.sqrt(np.matmul(np.matmul(diff_vect,comat),diff_vect))\n",
    "    min_class = 0\n",
    "    for i, m in enumerate(class_means[class_indices]):\n",
    "        diff_vect = np.array(test_sample[attribute_indices]-class_means[class_indices][i][attribute_indices])\n",
    "        comat = np.linalg.inv(class_cov_matrices[class_indices[i]])\n",
    "        d = np.sqrt(np.matmul(np.matmul(diff_vect,comat),diff_vect))\n",
    "        if(d < min_dist):\n",
    "            min_dist = d\n",
    "            min_class = i\n",
    "    return class_indices[min_class];\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "def run_nm_test(classes, attributes, distance_function):\n",
    "    chosen_train_samples = np.concatenate(\n",
    "        [train[classIndexes[i],:] for i in classes],\n",
    "        axis=0\n",
    "    ) # pick train samples from chosen classes\n",
    "    chosen_test_samples = np.concatenate(\n",
    "        [test[classIndexesTest[i],:] for i in classes],\n",
    "        axis=0\n",
    "    ) # filter out test samples that do not belong to the chosen classes\n",
    "    \n",
    "    test_classes = [sample[0] for sample in chosen_test_samples] # pick indices of classes that are tested\n",
    "    if(distance_function == 'euclidean'):\n",
    "        test_nearest_means = \\\n",
    "            [\n",
    "                 # cast classMeans to np.array to slice it with lists    \n",
    "                1+int(assign_nm_euclidean(test_sample, np.array(classMeans), classes, attributes))\n",
    "                for test_sample in chosen_test_samples # for each test sample from the chosen ones (i.e. belonging to the chosen classes)\n",
    "            ]\n",
    "    else:\n",
    "        \n",
    "        classCovMatrices = []\n",
    "        for i in range(CLASS_COUNT):\n",
    "            try:\n",
    "                # calculate covariance matrix only for selected attributes\n",
    "                classCovMatrices.append(covariance_matrix(train[classIndexes[i]][:,attributes]))\n",
    "            except:\n",
    "                classCovMatrices.append(None)\n",
    "        test_nearest_means = \\\n",
    "            [\n",
    "                1+int(assign_nm_machalan(test_sample, np.array(classMeans), classes, attributes, classCovMatrices)) # pick only these means that are from the chosen classes(cast to np.array to be able to slice it with a list)    \n",
    "                for test_sample in chosen_test_samples # for each test sample from the chosen ones (i.e. belonging to the chosen classes)\n",
    "            ]\n",
    "    \n",
    "    totalTestSamples = chosen_test_samples.shape[0]\n",
    "    correctSamples = 0\n",
    "    for i, sample in enumerate(chosen_test_samples):\n",
    "        if(test_nearest_means[i] == sample[0]): correctSamples+=1\n",
    "\n",
    "    return {\n",
    "        \"total_samples\": totalTestSamples,\n",
    "        \"correct_samples\": correctSamples,\n",
    "        \"confusion_matrix\": confusion_matrix(test_classes, test_nearest_means)\n",
    "    }\n",
    "\n",
    "\n",
    "def print_test_result(r:dict, matrix_class_indexes=None):\n",
    "    \"\"\" Prints formatted result dict of run_knn_test()\n",
    "    \"\"\"\n",
    "    print(\"MN: {} correct out of {} total. Accuracy: {:.2f}%\".format(r['correct_samples'], r['total_samples'], r['correct_samples']/r['total_samples']*100))\n",
    "    if(matrix_class_indexes):\n",
    "        print(\"{:8.8s}\".format(\"TRU\\PRED\"),end='|')\n",
    "        for index in matrix_class_indexes: #print top row\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[index]),end='|')\n",
    "        print()\n",
    "        for i, row in enumerate(r[\"confusion_matrix\"]): #print rows\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[i]),end='|')\n",
    "            for col in row:\n",
    "                print(\"{:8d}\".format(int(col)),end='|')\n",
    "            print()\n",
    "                \n",
    "PARAM_CLASSES = [2,4]\n",
    "PARAM_ATTRIBUTES = [4,15] \n",
    "print_test_result(run_nm_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 'euclidean'), PARAM_CLASSES)\n",
    "\n",
    "PARAM_CLASSES = [0,1,2,3,4,5,6,7]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13] \n",
    "\n",
    "print(\"\\nEUCLIDEAN DISTANCE\")\n",
    "print_test_result(run_nm_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 'euclidean'), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\nMACHALANOBIS' DISTANCE\")\n",
    "print_test_result(run_nm_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 'machalan'), PARAM_CLASSES)\n",
    "\n",
    "\n",
    "PARAM_CLASSES = [0,1,2,3]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13] \n",
    "print(\"\\nEUCLIDEAN DISTANCE\")\n",
    "print_test_result(run_nm_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 'euclidean'), PARAM_CLASSES)\n",
    "\n",
    "print(\"\\nMACHALANOBIS' DISTANCE\")\n",
    "print_test_result(run_nm_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 'machalan'), PARAM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
