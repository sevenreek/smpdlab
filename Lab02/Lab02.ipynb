{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 2 - algorytm *k* Najbli偶szych Ssiad贸w (*k*NN)\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest implementacja klasyfikatora *k* najbli偶szych ssiad贸w - *k*NN (*k Nearest Neighbors*) oraz zapoznanie si z innymi metrykami klasyfikacji.\n",
    "\n",
    "### Termin\n",
    "Zadanie nale偶y wykona tego samego dnia. \n",
    "\n",
    "### System oceniania\n",
    "\n",
    "| Liczba punkt贸w (procentowo) | Ocena |\n",
    "| :----                    | ---: |\n",
    "| [0-50)   | 2   |\n",
    "| [50-60)  | 3   |\n",
    "| [60-70)  | 3.5 |\n",
    "| [70-80)  | 4   |\n",
    "| [80-90)  | 4.5 |\n",
    "| [90-100] | 5   |\n",
    "\n",
    "<u>Punkty ujemne</u>\n",
    "\n",
    "* `ocena - 0.5` je偶eli zadanie wysano po laboratorium, ale < 7 dni; \n",
    "* `ocena - 1` je偶eli zadanie wysano w terminie pomidzy 7 a 14 dni;\n",
    "* `ocena - 1.5` je偶eli zadanie wysano po upywie 14 dni, ale przed ostatnim laboratorium;\n",
    "* `ocena = 2` je偶eli zadanie wysano po ostatnim laboratorium.\n",
    "\n",
    "<u>Uwaga:</u>\n",
    "\n",
    "Niedopuszczalne jest dzielenie si notatnikiem (plik `.ipynb`) z innymi studentami ani udostpnianie go w Internecie. Ka偶dy student powinien pobra notatnik samodzielnie z platformy WIKAMP.\n",
    "Wysyajc zadanie potwierdasz, 偶e wykonae je samodzielnie i jest to Twoja indywidualna praca a materia przedstawiony w tej pracy jest dla Ciebie zrozumiay. Prace bardzo podobne albo grupowe bd uznawane za plagiat.\n",
    "\n",
    "\n",
    "### Zbi贸r danych\n",
    "\n",
    "Zbi贸r danych znajduje si w katalogu `dataset/*`. Jest to zmodyfikowany zbi贸r danych znajdujcy si pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyanie zada\n",
    "\n",
    "Wszystkie pliki nale偶y spakowa archiwizatorem **zip** i przesa za porednictwem platformy WIKAMP. Poni偶ej oczekiwana zawarto archiwum:\n",
    "\n",
    "```\n",
    "+--  [IMIE.NAZWISKO].zip\n",
    "    +--  Lab02.ipynb\n",
    "    +--  dataset\n",
    "        +--  dataset.npz\n",
    "        +--  ReadMe.pdf\n",
    "```\n",
    "\n",
    "### Dodatkowe narzdzia\n",
    "\n",
    "Dopuszczalne jest korzystanie z bibliotek: `numpy`, `pandas`, `matplotlib`.\n",
    "Implementacja klasyfikatora powinna by wykonana samodzielnie (bez dodatkowych bibliotek).\n",
    "\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Nale偶y wykona nastpujce czynnoci w celu realizacji niniejszego zadania:\n",
    "* Wczytaj dane.\n",
    "* **Zaimplementuj klasyfikator *k* najbli偶szych ssiad贸w (*k*NN)** i uruchom predykcj.\n",
    "* Opisz jak zmieniaj si wyniki klasyfikatora dla r贸偶nych wartoci *k*, dla r贸偶nej liczby klas oraz dla r贸偶nej liczby cech.\n",
    "* Wywietl tablic pomyek (*confusion matrix*). W tym przypadku mo偶esz zastosowa gotow implementacj z biblioteki `scikit-learn` <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html>.\n",
    "* Odszukaj przynajmniej dwie inne (ni偶 accuracy) metryki przytatne w klasyfikacji na stronie <https://scikit-learn.org/stable/modules/model_evaluation.html> i opisz ich wyniki. Wytumacz czym si r贸偶ni i co mo偶na z nich odczyta.\n",
    "* Opisz r贸偶nic wynik贸w klasyfikacji obu algorytm贸w (NN i *k*NN)?\n",
    "\n",
    "\n",
    "> UWAGA: Wszystkie wykonane elementy zadania powinny posiada stosowne komentarze i opisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PONI呕EJ WYKONAJ ZADANIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2244, 16)\n"
     ]
    }
   ],
   "source": [
    "# creates labels\n",
    "ATTRIBUTE_NAMES = [\"Class\", \"Specimen No.\", \"Eccentricity\", \"Aspect Ratio\", \"Elongation\", \"Solidity\", \"Stochastic Convexity\", \"Isoperimetric Factor\", \"Maximal Indentation Depth\", \"Lobedness\", \"Average Intensity\", \"Average Contrast\", \"Smoothness\", \"Third moment\", \"Uniformity\", \"Entropy\"]\n",
    "CLASS_NAMES = \\\n",
    "\"\"\"Quercus suber \n",
    "Salix atrocinera \n",
    "Populus nigra \n",
    "Alnus sp. \n",
    "Quercus robur \n",
    "Crataegus monogyna \n",
    "Ilex aquifolium \n",
    "Nerium oleander \n",
    "Betula pubescens \n",
    "Tilia tomentosa \n",
    "Acer palmatum \n",
    "Celtis sp. \n",
    "Corylus avellana \n",
    "Castanea sativa \n",
    "Populus alba \n",
    "Acer negundo \n",
    "Taxus bacatta \n",
    "Papaver sp. \n",
    "Polypolium vulgare \n",
    "Pinus sp. \n",
    "Fraxinus sp. \n",
    "Primula vulgaris \n",
    "Erodium sp. \n",
    "Bougainvillea sp. \n",
    "Arisarum vulgare \n",
    "Euonymus japonicus \n",
    "Ilex perado ssp. azorica \n",
    "Magnolia soulangeana \n",
    "Buxus sempervirens \n",
    "Urtica dioica \n",
    "Podocarpus sp. \n",
    "Acca sellowiana \n",
    "Hydrangea sp. \n",
    "Pseudosasa japonica \n",
    "Magnolia grandiflora \n",
    "Geranium sp. \n",
    "Aesculus californica \n",
    "Chelidonium majus \n",
    "Schinus terebinthifolius \n",
    "Fragaria vesca \"\"\".split(\"\\n\")\n",
    "# import data\n",
    "import numpy as np\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "    train, test = data['train'], data['test']\n",
    "print(train.shape) # verify shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def euclidean_distance(sampleA, sampleB, attrIndices):\n",
    "    sqSum = 0\n",
    "    for ind in attrIndices:\n",
    "        sqSum += (sampleA[ind] - sampleB[ind])**2\n",
    "    sqSum = np.sqrt(sqSum)\n",
    "    return sqSum\n",
    "\n",
    "def get_most_common_class_in_distances(distances, k):\n",
    "    class_hits = {}\n",
    "    for sample in distances[:k]:\n",
    "        current_class_hits = class_hits.setdefault(int(sample['class_index']), 0)\n",
    "        class_hits[int(sample['class_index'])] = current_class_hits + 1\n",
    "    return max(class_hits.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "\n",
    "def assign_k_NN(sample, trainedSamples, attrIndices, k):\n",
    "    dtp = [('distance', float), ('class_index', int)]\n",
    "    distances = np.array(np.zeros((trainedSamples.shape[0],1)), dtype=dtp)\n",
    "    for i, trainedSample in enumerate(trainedSamples):\n",
    "        distances[i]['distance'] = euclidean_distance(sample, trainedSamples[i], attrIndices)\n",
    "        distances[i]['class_index'] = trainedSamples[i][0]\n",
    "    distances.sort(0, order='distance') # sort ascending\n",
    "    return get_most_common_class_in_distances(distances, k)\n",
    "\n",
    "#assign_k_NN(test[0], train, [4,5], 3)\n",
    "CLASS_COUNT = 40\n",
    "\n",
    "classIndexes = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexes.append([])\n",
    "for i, sample in enumerate(train):\n",
    "    classIndexes[int(sample[0])-1].append(int(i))\n",
    "\"\"\"\n",
    "for i, sampleClass in enumerate(classIndexes):\n",
    "    print(i,len(sampleClass))\n",
    "\"\"\"\n",
    "classIndexesTest = []\n",
    "for i in range(CLASS_COUNT):\n",
    "    classIndexesTest.append([])\n",
    "for i, sample in enumerate(test):\n",
    "    classIndexesTest[int(sample[0])-1].append(int(i))\n",
    "    \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def run_knn_test(classes, attributes, k):\n",
    "    chosen_train_samples = np.concatenate(\n",
    "        [train[classIndexes[i],:] for i in classes],\n",
    "        axis=0\n",
    "    )\n",
    "    chosen_test_samples = np.concatenate(\n",
    "        [test[classIndexesTest[i],:] for i in classes],\n",
    "        axis=0\n",
    "    )\n",
    "    #print(f\"Train samples: {chosen_train_samples.shape}. Test samples: {chosen_test_samples.shape}\")\n",
    "    test_classes = [sample[0] for sample in chosen_test_samples]\n",
    "    test_nearest_neigbours = \\\n",
    "        [int(assign_k_NN(test_sample, chosen_train_samples, attributes, k)) for test_sample in chosen_test_samples]\n",
    "\n",
    "    totalTestSamples = chosen_test_samples.shape[0]\n",
    "    correctSamples = 0\n",
    "    for i, sample in enumerate(chosen_test_samples):\n",
    "        if(test_nearest_neigbours[i] == sample[0]): correctSamples+=1\n",
    "\n",
    "    return {\n",
    "        \"total_samples\": totalTestSamples,\n",
    "        \"correct_samples\": correctSamples,\n",
    "        \"confusion_matrix\": confusion_matrix(test_classes, test_nearest_neigbours)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_result(k, r:dict, matrix_class_indexes=None):\n",
    "    \"\"\" Prints formatted result dict of run_knn_test()\n",
    "    \"\"\"\n",
    "    print(\"{}NN: {} correct out of {} total. Accuracy: {:.2f}%\".format(k, r['correct_samples'], r['total_samples'], r['correct_samples']/r['total_samples']*100))\n",
    "    if(matrix_class_indexes):\n",
    "        print(\"{:8.8s}\".format(\"\"),end='|')\n",
    "        for index in matrix_class_indexes: #print top row\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[index]),end='|')\n",
    "        print()\n",
    "        for i, row in enumerate(r[\"confusion_matrix\"]): #print rows\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[i]),end='|')\n",
    "            for col in row:\n",
    "                print(\"{:8d}\".format(int(col)),end='|')\n",
    "            print()\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing if 1-NN is lab01 NN (Zadanie 1.9):\n",
      "{'total_samples': 110, 'correct_samples': 110, 'confusion_matrix': array([[55,  0],\n",
      "       [ 0, 55]], dtype=int64)}\n",
      "Expected accuracy: 100%\n",
      "\n",
      "Testing if 1-NN is lab01 NN (Zadanie 1.9):\n",
      "{'total_samples': 242, 'correct_samples': 143, 'confusion_matrix': array([[41,  2,  0,  1,  0],\n",
      "       [17, 20,  0, 17, 12],\n",
      "       [ 0,  0, 33,  0,  0],\n",
      "       [ 2,  5,  0, 20,  6],\n",
      "       [ 0, 17,  0, 20, 29]], dtype=int64)}\n",
      "Expected accuracy: 59.09%\n",
      "\n",
      "\n",
      "Testing 1/5/10/25NN with 8 classes and 5 attributes\n",
      "1NN: 344 correct out of 429 total. Accuracy: 80.19%\n",
      "5NN: 347 correct out of 429 total. Accuracy: 80.89%\n",
      "10NN: 355 correct out of 429 total. Accuracy: 82.75%\n",
      "\n",
      "Testing 1/5/10/25NN with 12 classes and 5 attributes\n",
      "1NN: 455 correct out of 660 total. Accuracy: 68.94%\n",
      "5NN: 458 correct out of 660 total. Accuracy: 69.39%\n",
      "10NN: 453 correct out of 660 total. Accuracy: 68.64%\n",
      "\n",
      "Testing 1/5/10/25NN with 4 classes and 5 attributes\n",
      "1NN: 125 correct out of 176 total. Accuracy: 71.02%\n",
      "5NN: 130 correct out of 176 total. Accuracy: 73.86%\n",
      "10NN: 136 correct out of 176 total. Accuracy: 77.27%\n",
      "\n",
      "Testing 1/5/10/25NN with 8 classes and 10 attributes\n",
      "1NN: 119 correct out of 176 total. Accuracy: 67.61%\n",
      "5NN: 130 correct out of 176 total. Accuracy: 73.86%\n",
      "10NN: 131 correct out of 176 total. Accuracy: 74.43%\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "        \n",
    "print(\"\\nTesting if 1-NN is lab01 NN (Zadanie 1.9):\")\n",
    "PARAM_K = 1\n",
    "PARAM_CLASSES = [2, 4]\n",
    "PARAM_ATTRIBUTES = [4,15]\n",
    "print(run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "print(\"Expected accuracy: 100%\")\n",
    "\n",
    "print(\"\\nTesting if 1-NN is lab01 NN (Zadanie 1.9):\")\n",
    "PARAM_K = 1\n",
    "PARAM_CLASSES = [22,23,24,25,26]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13]\n",
    "print(run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "print(\"Expected accuracy: 59.09%\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nTesting 1/5/10/25NN with 8 classes and 5 attributes\")\n",
    "PARAM_CLASSES = [0,1,2,3,4,5,6,7]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13] \n",
    "print_test_result(1, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 1))\n",
    "PARAM_K = 5\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "PARAM_K = 10\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "\n",
    "\n",
    "print(\"\\nTesting 1/5/10/25NN with 12 classes and 5 attributes\")\n",
    "PARAM_CLASSES = [0,1,2,3,4,5,6,7, 8,9,10,11]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13] \n",
    "print_test_result(1, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 1))\n",
    "PARAM_K = 5\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "PARAM_K = 10\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "\n",
    "\n",
    "print(\"\\nTesting 1/5/10/25NN with 4 classes and 5 attributes\")\n",
    "PARAM_CLASSES = [0,1,2,3]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13] \n",
    "print_test_result(1, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 1))\n",
    "PARAM_K = 5\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "PARAM_K = 10\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "\n",
    "\n",
    "print(\"\\nTesting 1/5/10/25NN with 8 classes and 10 attributes\")\n",
    "PARAM_CLASSES = [0,1,2,3]\n",
    "PARAM_ATTRIBUTES = [4,5,6,7,8,9,10,11,12,13] \n",
    "print_test_result(1, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, 1))\n",
    "PARAM_K = 5\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n",
    "PARAM_K = 10\n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowanie metody k-NN (k>1) generalnie doprowadzio do zauwa偶alnej poprawy wynik贸w klasyfikacji. Metoda ta doprowadzia przede wszystkim do wyeliminowania tych przypadk贸w w kt贸rych metoda 1-NN zaklasyfikowaaby badan pr贸bk do bdnej klasy na podstawie pr贸bki nienaturalnie oddalonej od reszty pr贸bek z klasy. \n",
    "\n",
    "Przy jednej z konfiguracji (12 klas, 5 atrybut贸w) u偶ycie metody 10-NN dao gorsze rezultaty ni偶 metod 5-NN, i 1-NN. Parametr k musi zosta dobrany odpowiednio do badanego zestawu i jego zwikszanie nie zawsze doprowadzi do poprawy celnoci klasyfikacji, zwaszcza jeli wybrane do klasyfikacji cechy nie s dostatecznie dyskryminujce.\n",
    "\n",
    "Taka sytuacja prawdopodobnie wydarzya si w ostatniej konfiguracji (8 klas, 10 atrybut贸w), gdzie mimo wikszej iloci branych pod uwag cech wyniki klasyfikacji s gorsze ni偶 w konfiguracji korzystajcej z mniejszej iloci atrybut贸w (5), przy tej samej iloci klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5NN: 347 correct out of 429 total. Accuracy: 80.89%\n",
      "        |Quercus |Salix at|Populus |Alnus sp|Quercus |Crataegu|Ilex aqu|Nerium o|\n",
      "Quercus |      47|       1|       0|       7|       0|       0|       0|       0|\n",
      "Salix at|      11|      33|       0|       0|       0|       0|       0|       0|\n",
      "Populus |       9|       2|      33|      11|       0|       0|       0|       0|\n",
      "Alnus sp|       5|       0|       0|      17|       0|       0|       0|       0|\n",
      "Quercus |       0|       0|       0|       0|      53|       0|       2|       0|\n",
      "Crataegu|       0|       0|       0|       0|       0|      44|       0|       0|\n",
      "Ilex aqu|       3|      17|       0|       6|       4|       0|      36|       0|\n",
      "Nerium o|       0|       0|       0|       0|       4|       0|       0|      84|\n"
     ]
    }
   ],
   "source": [
    "def print_test_result(k, r:dict, matrix_class_indexes=None):\n",
    "    print(\"{}NN: {} correct out of {} total. Accuracy: {:.2f}%\".format(k, r['correct_samples'], r['total_samples'], r['correct_samples']/r['total_samples']*100))\n",
    "    if(matrix_class_indexes):\n",
    "        print(\"{:8.8s}\".format(\"\"),end='|')\n",
    "        for index in matrix_class_indexes: #print top row\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[index]),end='|')\n",
    "        print()\n",
    "        for i, row in enumerate(r[\"confusion_matrix\"]): #print rows\n",
    "            print(\"{:.8s}\".format(CLASS_NAMES[i]),end='|')\n",
    "            for col in row:\n",
    "                print(\"{:8d}\".format(int(col)),end='|')\n",
    "            print()\n",
    "                \n",
    "PARAM_K = 5\n",
    "PARAM_CLASSES = [0,1,2,3,4,5,6,7]\n",
    "PARAM_ATTRIBUTES = [4,7,9,11,13] \n",
    "print_test_result(PARAM_K, run_knn_test(PARAM_CLASSES, PARAM_ATTRIBUTES, PARAM_K), PARAM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W analizowanym przypadku Salix atrocinerea by czsto bdnie klasyfikowany jako Quercus robur; a Ilex aquifolium jako Salix atrocinerea. Licie posiadaj m.in do podobny ksztat pod wzgldem dugoci i szerokoci co jest prawdopodobnie przyczyn tego stanu rzeczy. \n",
    "<img src=\"https://www.sorianatural.com/storage/img/F0000001472_plantas_web_ok_oak.jpg\" style=\"height:200px;\"> \n",
    "Quercus robur\n",
    "<img src=\"https://www.arbolapp.es/imagenes/especies/especie_079_01.jpg\" style=\"height:200px;\"> \n",
    "Salix atrocinerea\n",
    "<img src=\"https://www.monaconatureencyclopedia.com/wp-content/uploads/2008/08/le_foglie_ed_i_frutti_rossi_persistenti_d_inverno_fanno_allegria_e_l_ilex_aquifolium_e_sempre_stato_considerato_un_porta_fortuna.jpg\" style=\"height:200px;\"> \n",
    "Ilex aquifolium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>F1</h3>\n",
    "Recall jest to procent poprawnych klasyfikacji obiekt贸w danej klasy w stosunku do liczby obiekt贸w z tej klasy. Daje informacj jak skutecznie klasyfikator wykrywa obiekty danej klasy.\n",
    "\n",
    "Precision jest to procent poprawnych klasyfikacji obiekt贸w danej klasy w stosunku do caej liczby obiekt贸w kt贸re zostay zaklasyfikowane do danej klasy. Daje informacj ile z obiekt贸w uznanych za dan klas faktycznie do niej nale偶y.\n",
    "\n",
    "F1 jest metryk majc uwzgldni obie te wartoci w jednej liczbie. \n",
    "Do jej obliczenia wykorzystana jest rednia harmoniczna:\n",
    "$$F_{\\beta}=(1+\\beta^2)\\bullet \\frac{precision \\bullet recall}{(\\beta^2 \\bullet precision)+recall}$$\n",
    "Dla $$\\beta==1$$ oba parametry s tak samo wa偶ne i ze wzgldu na wykorzystanie redniej harmonicznej jeli jeden z nich bdzie bliski zera caa rednia r贸wnie偶 bdzi osiga niskie wartoci. Zwikszenie $$\\beta$$ stawia wiksz wag na recall a zmniejszenie poni偶ej jednoci na precision.\n",
    "\n",
    "Wykorzystanie F1 pozwala wykry sytuacje w kt贸rej klasa mniej liczniej reprezentowana w zbiorze testowym nie osiga takiego samego poziomu celnoci klasyfikacji jak inne.\n",
    "\n",
    "<h3>Balanced Accuracy</h3>\n",
    "Specificity jest ilorazem liczby pr贸bek niezaklasyfikowanych do analizowanej klasy do caej liczby pr贸bek nienale偶cych do tej klasy. Jest miar tego jak skutecznie odrzucane s obiekty pochodzce z innych klas.\n",
    "\n",
    "Balanced Accuracy jest redni arytmetyczn wartoci recall i specificity.\n",
    "$$balanced accuracy=\\frac{recall+specificity}{2}$$\n",
    "Spenia to podobne zadanie co F1. W przypadku niezbalansowanych klas pozwala na wykrycie problem贸w z dyskryminacj tych mniej licznych. R贸偶nica wynika z tego 偶e F1 nie bierze pod uwag pr贸bek niezaklasyfikowanych do danej klasy, balanced accuracy sprawdzi si lepiej jeli zale偶y nam na uwzgldnieniu tego jak skutecznie klasyfikator odrzuca prawdziwie bdne klasy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(True): # get_most_common_class_in_distances\n",
    "    print(\"BEGIN TEST\")\n",
    "    dtp = [('distance', float), ('class_index', int)]\n",
    "    distances = np.array([(10,1),(20,2),(21,2),(32,3),(30,3),(50,5),(31,3)], dtype=dtp)\n",
    "    distances[:].sort(0, order='distance') # sort descending\n",
    "    print(distances)\n",
    "    print(get_most_common_class_in_distances(distances, 1))\n",
    "    print(get_most_common_class_in_distances(distances, 2))\n",
    "    print(get_most_common_class_in_distances(distances, 3))\n",
    "    print(get_most_common_class_in_distances(distances, 6))\n",
    "    print(\"END TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
